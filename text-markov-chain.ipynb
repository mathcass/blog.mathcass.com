{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple implementation of a Markov Chain text generator in Python inspired by an [implementation](https://golang.org/doc/codewalk/markov/) in Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MarkovChain:\n",
    "    \n",
    "    END = '_END_'\n",
    "    \n",
    "    def __init__(self, k=2, tokenizer=None):\n",
    "        \"\"\"Initialize a Markov Chain with k prefix elements (k-gram)\"\"\"\n",
    "        \n",
    "        self.k = k\n",
    "        if tokenizer is None:\n",
    "            self.tokenizer = self.default_tokenizer\n",
    "        self.chain = {}\n",
    "        \n",
    "    \n",
    "    def feed(self, text):\n",
    "        \"\"\"Feeds the chain with input text\"\"\"\n",
    "        tokens = self.tokenizer(text) + [self.END]\n",
    "        \n",
    "        for i in range(len(tokens) - self.k):\n",
    "            prefix = \" \".join(tokens[i:i+self.k])\n",
    "            self.chain.setdefault(prefix, [])\n",
    "            self.chain[prefix].append(tokens[i+self.k])\n",
    "\n",
    "    \n",
    "    def generate(self, seed_text, maxlen=100):\n",
    "        \"\"\"Generates new text from the given seed\"\"\"\n",
    "        \n",
    "        seed_tokens = self.tokenizer(seed_text)\n",
    "        assert len(seed_tokens) == self.k, f\"Invalid seed length, must be of length {self.k}\"\n",
    "        \n",
    "        text = [] + seed_tokens\n",
    "        \n",
    "        for i in range(maxlen):\n",
    "            prefix = \" \".join(text[i:i+self.k])\n",
    "            choices = self.chain.setdefault(prefix, [])\n",
    "            \n",
    "            if not choices:\n",
    "                # Otherwise, we have nothing left to build\n",
    "                return text\n",
    "            \n",
    "            next_token = random.choice(choices)\n",
    "            \n",
    "            if next_token == self.END:\n",
    "                return self.format_output(text)\n",
    "            else:\n",
    "                text += [next_token]\n",
    "        \n",
    "        return self.format_output(text)\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def format_output(tokens):\n",
    "        \"\"\"Formats the list of tokens for output\"\"\"\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    @staticmethod\n",
    "    def default_tokenizer(text):\n",
    "        \"\"\"Default tokenizer splitting on spaces\"\"\"\n",
    "        return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MarkovChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socrates was a dog\n",
      "Socrates was a man and a thinker\n",
      "Socrates was a man\n",
      "Socrates was a man and a thinker\n",
      "Socrates was a dog\n",
      "Socrates was a man\n",
      "Socrates was a man\n",
      "Socrates was a dog\n",
      "Socrates was a dog\n",
      "Socrates was a man\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Socrates was a man\",\n",
    "    \"Plato was a man\",\n",
    "    \"Aristotle was a man\",\n",
    "    \"He was a man and a thinker\",\n",
    "    \"Scooby Doo was a dog\",\n",
    "    \"I am not a number! I am a free man!\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    mc.feed(text)\n",
    "    \n",
    "for _ in range(10):\n",
    "    print(mc.generate(\"Socrates was\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
